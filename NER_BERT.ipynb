{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets -q"
      ],
      "metadata": {
        "id": "r1Srs6pMtA9F"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JTSm706Lsyvh"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\n",
        "    \"conll2003\",\n",
        "    trust_remote_code=True\n",
        ").remove_columns([\"id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZmi22vBtDnN",
        "outputId": "42765077-fcac-4148-ecdc-aac9c2376c78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"].to_pandas().head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "MIEboI3ItPmB",
        "outputId": "968a58ad-f4bb-4773-8feb-403835c8cfe1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tokens  \\\n",
              "0  [EU, rejects, German, call, to, boycott, Briti...   \n",
              "1                                 [Peter, Blackburn]   \n",
              "2                             [BRUSSELS, 1996-08-22]   \n",
              "3  [The, European, Commission, said, on, Thursday...   \n",
              "4  [Germany, 's, representative, to, the, Europea...   \n",
              "\n",
              "                                            pos_tags  \\\n",
              "0                [22, 42, 16, 21, 35, 37, 16, 21, 7]   \n",
              "1                                           [22, 22]   \n",
              "2                                           [22, 11]   \n",
              "3  [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 3...   \n",
              "4  [22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 2...   \n",
              "\n",
              "                                          chunk_tags  \\\n",
              "0                [11, 21, 11, 12, 21, 22, 11, 12, 0]   \n",
              "1                                           [11, 12]   \n",
              "2                                           [11, 12]   \n",
              "3  [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 1...   \n",
              "4  [11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 1...   \n",
              "\n",
              "                                            ner_tags  \n",
              "0                        [3, 0, 7, 0, 0, 0, 7, 0, 0]  \n",
              "1                                             [1, 2]  \n",
              "2                                             [5, 0]  \n",
              "3  [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...  \n",
              "4  [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a01bf23-c612-4e1e-8767-5cdc921b158d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>chunk_tags</th>\n",
              "      <th>ner_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n",
              "      <td>[22, 42, 16, 21, 35, 37, 16, 21, 7]</td>\n",
              "      <td>[11, 21, 11, 12, 21, 22, 11, 12, 0]</td>\n",
              "      <td>[3, 0, 7, 0, 0, 0, 7, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Peter, Blackburn]</td>\n",
              "      <td>[22, 22]</td>\n",
              "      <td>[11, 12]</td>\n",
              "      <td>[1, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[BRUSSELS, 1996-08-22]</td>\n",
              "      <td>[22, 11]</td>\n",
              "      <td>[11, 12]</td>\n",
              "      <td>[5, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The, European, Commission, said, on, Thursday...</td>\n",
              "      <td>[12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 3...</td>\n",
              "      <td>[11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 1...</td>\n",
              "      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Germany, 's, representative, to, the, Europea...</td>\n",
              "      <td>[22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 2...</td>\n",
              "      <td>[11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 1...</td>\n",
              "      <td>[5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a01bf23-c612-4e1e-8767-5cdc921b158d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a01bf23-c612-4e1e-8767-5cdc921b158d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a01bf23-c612-4e1e-8767-5cdc921b158d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13a58b81-1b54-4de2-8cbd-4de97db99e10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13a58b81-1b54-4de2-8cbd-4de97db99e10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13a58b81-1b54-4de2-8cbd-4de97db99e10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset[\\\"train\\\"]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\"B-\":beginning \"I-\":inside --> start of the phrase , part of previous phrase\n",
        "label2id={\n",
        "    \"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-ORG\": 3, \"I-ORG\": 4,\"B-LOC\": 5, \"I-LOC\": 6, \"B-MISC\": 7, \"I-MISC\": 8\n",
        "}\n",
        "id2label={v:k for k,v in label2id.items()}\n",
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc8hyLfQtTi-",
        "outputId": "01f06528-f108-42e8-f534-948f6ccb259a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-PER': 1,\n",
              " 'I-PER': 2,\n",
              " 'B-ORG': 3,\n",
              " 'I-ORG': 4,\n",
              " 'B-LOC': 5,\n",
              " 'I-LOC': 6,\n",
              " 'B-MISC': 7,\n",
              " 'I-MISC': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example=dataset[\"train\"][848]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYqIe6MxwIVB",
        "outputId": "6f12ada0-d7ba-4830-d633-d92b90e1f59d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['Dean',\n",
              "  'Palmer',\n",
              "  'hit',\n",
              "  'his',\n",
              "  '30th',\n",
              "  'homer',\n",
              "  'for',\n",
              "  'the',\n",
              "  'Rangers',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 22, 38, 29, 16, 21, 15, 12, 23, 7],\n",
              " 'chunk_tags': [11, 12, 21, 11, 12, 12, 13, 11, 12, 0],\n",
              " 'ner_tags': [1, 2, 0, 0, 0, 0, 0, 0, 3, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "#model=AutoModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu3WvjrvxO6J",
        "outputId": "4b07f2c0-23ee-4812-eb5f-b6bedc787fd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id=tokenizer.encode(example[\"tokens\"],is_split_into_words=True)\n",
        "token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS8IQ3_UxnS3",
        "outputId": "b224261e-9f8e-45c5-979c-3c7e39f1ad18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 4285, 8450, 1855, 1117, 13631, 1313, 1197, 1111, 1103, 6838, 119, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\" \".join(example[\"tokens\"])) # is_split_into_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wC5MddQxujv",
        "outputId": "4afa580b-28c2-4a61-baf1-b3e667ab238f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 4285, 8450, 1855, 1117, 13631, 1313, 1197, 1111, 1103, 6838, 119, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYrJ5HGbx6PM",
        "outputId": "8a832b09-accd-477d-d71b-276685b2cb21"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Dean',\n",
              " 'Palmer',\n",
              " 'hit',\n",
              " 'his',\n",
              " '30th',\n",
              " 'home',\n",
              " '##r',\n",
              " 'for',\n",
              " 'the',\n",
              " 'Rangers',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the root of each token\n",
        "token_ids=tokenizer(\n",
        "      example[\"tokens\"],\n",
        "      is_split_into_words=True,\n",
        "      truncation=True\n",
        "  )\n",
        "token_ids.word_ids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv8T6-A00ymR",
        "outputId": "10fd22b5-ea67-4544-f6f2-cc64cc2e0bfb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, None]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels(examples):\n",
        "  token_ids=tokenizer(\n",
        "      examples[\"tokens\"],\n",
        "      truncation=True,\n",
        "      is_split_into_words=True\n",
        "  )\n",
        "  labels=examples[\"ner_tags\"]\n",
        "  updated_labels=[]\n",
        "  for idx,label in enumerate(labels):\n",
        "    word_ids=token_ids.word_ids(batch_index=idx)\n",
        "    previous_word_idx=None\n",
        "    label_ids=[]\n",
        "    for word_idx in word_ids:\n",
        "      if word_idx!=previous_word_idx:\n",
        "        previous_word_idx=word_idx\n",
        "        #print(label)\n",
        "        updated_label= -100 if word_idx is None else label[word_idx]\n",
        "        label_ids.append(updated_label)\n",
        "      elif word_idx is None:\n",
        "        label_ids.append(-100)\n",
        "      else:\n",
        "        updated_label=label[word_idx]\n",
        "        if updated_label%2==1:\n",
        "          updated_label+=1\n",
        "        label_ids.append(updated_label)\n",
        "    updated_labels.append(label_ids)\n",
        "  token_ids[\"labels\"]=updated_labels\n",
        "  return token_ids"
      ],
      "metadata": {
        "id": "dsQbIcMxyZ6m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized=dataset.map(align_labels,batched=True)"
      ],
      "metadata": {
        "id": "K1SweTmY6XU9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized[\"train\"][848]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmRwc9dF6XR6",
        "outputId": "a21f1f5d-449c-4b36-bc59-63628d8689a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tokens': ['Dean',\n",
              "  'Palmer',\n",
              "  'hit',\n",
              "  'his',\n",
              "  '30th',\n",
              "  'homer',\n",
              "  'for',\n",
              "  'the',\n",
              "  'Rangers',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 22, 38, 29, 16, 21, 15, 12, 23, 7],\n",
              " 'chunk_tags': [11, 12, 21, 11, 12, 12, 13, 11, 12, 0],\n",
              " 'ner_tags': [1, 2, 0, 0, 0, 0, 0, 0, 3, 0],\n",
              " 'input_ids': [101,\n",
              "  4285,\n",
              "  8450,\n",
              "  1855,\n",
              "  1117,\n",
              "  13631,\n",
              "  1313,\n",
              "  1197,\n",
              "  1111,\n",
              "  1103,\n",
              "  6838,\n",
              "  119,\n",
              "  102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'labels': [-100, 1, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, -100]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(token_id)==len(tokenized[\"train\"][848][\"labels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP9LQR8z6XN-",
        "outputId": "cb126e95-b36c-4621-fdec-505585a36967"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "WnSKiQS-v_8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install evaluate seqeval -q"
      ],
      "metadata": {
        "id": "Wm2Qq7wYwFYy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "seqeval=evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "nuk25EIQv_o6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metric(eval_pred):\n",
        "  # eval_pred (logits,labels)\n",
        "  logits,labels=eval_pred\n",
        "  # logits shape (b,n_tokens,n_labels), labels_shape (b,n_token)\n",
        "  predictions=np.argmax(logits,dim=2) # predictions shape (b,n_tokens,1)\n",
        "\n",
        "  true_pres=[]\n",
        "  true_labels=[]\n",
        "  for pred,label in zip(predictions,labels):\n",
        "    for token_pred,token_label in zip(pred,label):\n",
        "      if token_label!=-100:\n",
        "        true_pres.append([id2label[token_pred]])\n",
        "        true_labels.append([id2label[token_label]])\n",
        "  results=seqeval.compute(\n",
        "      predictions=true_pres,references=true_labels\n",
        "  )\n",
        "  return {\"f1\":results[\"overall_f1\"]}\n"
      ],
      "metadata": {
        "id": "Hqj5dPAm00lU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning Bert"
      ],
      "metadata": {
        "id": "i-FlRN6t0ZlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm8zeyqv1h2l",
        "outputId": "82a5a30f-25a3-483e-b791-8a4282bc768e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 29 13:50:16 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.trainer import TrainingArguments,Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "0lqHVpdXy_Sr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=AutoModelForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        "    )\n",
        "model=model.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0YYj4yW0sqH",
        "outputId": "2df57d12-dd5f-45e6-9b90-ab8f76a7bb13"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model(torch.tensor([tokenizer.encode(\"Hello From me!\")]).to(\"cuda\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds8JLQwS1l0m",
        "outputId": "e85eb77c-2017-458e-e566-2a87276bfa74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TokenClassifierOutput(loss=None, logits=tensor([[[-0.3278, -0.0306,  0.1691,  0.2251, -0.1014, -0.7512,  0.1705,\n",
              "          -0.2649, -0.3330],\n",
              "         [-0.3787,  0.3154,  0.0583,  0.1973, -0.2377, -0.7580,  0.1071,\n",
              "          -0.3590, -0.5915],\n",
              "         [ 0.0057,  0.0916, -0.0197, -0.1194, -0.2122, -0.4089,  0.1568,\n",
              "          -0.1600, -0.2075],\n",
              "         [ 0.0369, -0.0212, -0.0729, -0.0329, -0.2873, -0.0314, -0.1700,\n",
              "          -0.2954, -0.3013],\n",
              "         [ 0.1317, -0.0447,  0.2847, -0.4128, -0.3720,  0.0343, -0.1409,\n",
              "          -0.2729, -0.2554],\n",
              "         [ 0.0396,  0.3617, -0.6330, -0.4231,  0.3907,  0.0203,  0.2813,\n",
              "          -0.2573, -0.2564]]], device='cuda:0', grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ft model \"bert-base-cased\"\n",
        "args=TrainingArguments(\n",
        "    \"nerclassifications\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "dNE19N712sLt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datacollator=DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "E-iDIjzh6Iwk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=datacollator,\n",
        "    compute_metrics=compute_metric\n",
        ")"
      ],
      "metadata": {
        "id": "Mp3WAL2G4Tb-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "VL8CBAR94W52",
        "outputId": "eba54c97-4844-4f94-b673-b94db0a287dc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='878' max='878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [878/878 02:46, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.222700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=878, training_loss=0.16162384180924888, metrics={'train_runtime': 167.6079, 'train_samples_per_second': 83.773, 'train_steps_per_second': 5.238, 'total_flos': 351240792638148.0, 'train_loss': 0.16162384180924888, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"ner_model\")"
      ],
      "metadata": {
        "id": "lVmW1HKXjWfx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "token_classifier=pipeline(\n",
        "    \"token-classification\",\n",
        "    model=\"ner_model\"\n",
        ")\n",
        "token_classifier(\"my name Abdeljalil\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBOwLwFCjj9K",
        "outputId": "016efda9-38d3-419d-ca40-e0b63d8093f6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-PER',\n",
              "  'score': 0.98813665,\n",
              "  'index': 3,\n",
              "  'word': 'Abd',\n",
              "  'start': 8,\n",
              "  'end': 11},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.98896563,\n",
              "  'index': 4,\n",
              "  'word': '##el',\n",
              "  'start': 11,\n",
              "  'end': 13},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.9941147,\n",
              "  'index': 5,\n",
              "  'word': '##ja',\n",
              "  'start': 13,\n",
              "  'end': 15},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.99390644,\n",
              "  'index': 6,\n",
              "  'word': '##li',\n",
              "  'start': 15,\n",
              "  'end': 17},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.98908395,\n",
              "  'index': 7,\n",
              "  'word': '##l',\n",
              "  'start': 17,\n",
              "  'end': 18}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "OXVZXoE66rdv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0a281783-5605-4d48-b5ba-bd764303e05a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-86fb30049a58>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TrainingArguments?"
      ],
      "metadata": {
        "id": "gcsAcpzk9DOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ANFMk7A_QSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}